---
{"dg-publish":true,"dg-permalink":"JVM 调优经历","permalink":"/JVM 调优经历/"}
---


#JVM #线上问题排查 

## 1. 堆内存调整

### 现象

集群内 Pod 重启频繁，线程池拒绝增多。

### 分析

分析手段：
- 根据公司自研的，基于阿里的 Arthas 的 **Bistoury** 平台来观测 JVM 的堆内存情况（新生代、老年代等占比数据）
- 通过 **jmap** 进行 dump 出堆内存快照：发现**并没有大对象存在**，引发 OOM 的可能
- 通过 **jstat** 观察 GC 的次数和耗时：发现 GC **并不频繁**。

所以考虑是**堆外内存**导致的 OOM，引发容器的重启。

#### 堆外内存

起初，容器的堆内存 = Pod 内存 x 0.8 = 12 x 0.8 = **9.6G**

由于项目使用了 NIO 的请求框架，底层使用 *DirectBuffer* 分配在堆外内存（直接内存）的，但是堆外只留了 2.4GB，导致频繁的 OOM 重启。

### 做法

1. 最终调整堆内存到 **6GB**。
2. 为了避免重启带来的影响：做线程池和**接口预热**，模拟线上的并发流量。

## 2. D 环境线程数调整

### 起因

D 环境虚机 **swap 报警**，物理内存不够用了。

通过 top 命令查看 JVM 进程的内存情况：申请的内存 **10.11g** 实际使用了 **4.7g**  

![](/img/user/attachments/images/image2021-4-21_20-20-20.png)

### 分析

通过 NMT、堆外 Buffer 占用统计脚本分析堆内、非堆、堆外的内存情况。

栈内存占用高达 **2G** 多，通过 *jstack* 统计所有线程的信息（所有线程、活跃线程等）

结论：一共有有 **2.5k** 左右线程数，日常活跃线程只有 **200** 多个，线程的活跃率在 **8%**

### 做法

由于 D 环境 QPS 并不高，并不需要这么多的线程。

根据识别出 D 环境，初始化时设置特定的线程池参数，减少线程栈的内存占用。