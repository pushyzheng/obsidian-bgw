---
{"dg-publish":true,"dg-permalink":"分布式缓存","permalink":"/分布式缓存/"}
---


## 谈一谈缓存穿透、缓存击穿和缓存雪崩，以及解决办法?

1. ==缓存雪崩==
	- 大量缓存数据在**同一时间**失效，导致大量请求直接访问数据库，造成数据库奔溃
	- 解决方案：
		- 打散过期时间（增加随机）
		- 多级缓存
		- 缓存预热和预加载
		- 熔断限流和服务降级：在高负载时限制请求访问数据库
2. ==缓存穿透==
	- 查询的数据既不在缓存，也不在数据库（不会写缓存），导致每次都读 DB
	- 解决方案
		- 缓存空结果，避免重复查询数据库
		- 使用布隆过滤器提前拦截
3. ==缓存击穿==
	- 某个**热点数据**缓存失效时，瞬间大量请求同时访问数据库，造成数据库压力骤增
	- 解决方案
		- 热点数据**永不过期**，并搭配异步刷新缓存，避免失效
		- 加互斥锁或分布式锁：保证同一时间**只有一个**请求去数据库查询并重建缓存

## 缓存雪崩、缓存击穿有什么区别吗？

1. 缓存雪崩是缓存的**大面积失效**或服务器不可用
2. 缓存击穿则是**某几个**热点 Key 失效，像是被击穿了一个很小的「洞」

## 常见的缓存更新策略？

[比较经典的三种缓存更新策略](obsidian://open?vault=%E7%AC%94%E8%AE%B0&file=src%2Funarchived%2F%E7%BB%8F%E5%85%B8%E7%BC%93%E5%AD%98%E6%9B%B4%E6%96%B0%E7%AD%96%E7%95%A5)有：

1. *Cache Aside*
	- 读缓存，无则穿透再回写
	- 写库，再删除缓存
	- 优点：比较主流，实现简单，不一致的**概率小**
2. *Read/Write Through*
	- 读缓存，同上
	- 写库，同上
	- 优点：同上，但在代码上更简洁和抽象
	- 缺点：代码稍微复杂
3. *Write Behind*
	- 直接读缓存
	- 更新缓存，再**异步写库**
	- 优点：写 I/O 效率比较高，适合频繁写
	- 缺点：一致性不高，实现复杂

## 其他缓存更新方案存在什么问题？

1. 先更新 DB，后更新缓存
	- 两个并发的写请求，很容易导致**并发修改缓存**，出现数据不一致
	- 缺点：不是一种懒加载的模式，在写多读少的情况下，很容易刚更新完又被更新了
2. 先删缓存，后更新 DB
	- 在更新 DB 前读取数据，又在另一个线程更新 DB 数据后，写入缓存

## 分布式缓存有哪些不一致的情况？

1. 写 DB 和删除缓存**不是原子的**
	- 如果写 DB 失败，而缓存没有删除，则出现脏数据
	- 解决方案：
		- 重试：消息队列做重试补偿
		- 监听 binlog 删除：可以使用 [[src/分布式/canal\|canal]]
2. **高并发**场景的不一致
	- 某个线程在 DB 数据更新前读取出来
	- 又在 DB 数据更新后将写入缓存
3. **主从架构**导致不一致
	- 主从同步存在延迟：
		- 写：写**主库**后删除缓存
		- 读：穿透到**从库**读取到旧的数据
	- 解决方案：
		- 抛弃主从：读写都走主库
		- 区分核心业务：对及时和一致性高的业务，走主库
		- 延迟双删：先删缓存，间隔一段时间后再次删除

## 如何处理缓存的热 Key？

1. 什么是热 Key？
	- 流量太集中，单个分片的结点资源达到上限，**负载不均匀**
	- 热 Key 请求同时落在一个 Redis 实例上，无法通过扩容解决
2. 如何发现热 Key？
	- 凭借业务经验预估（如某些城市的热 Key 概率高）
	- 在代码层、代理层做统计
3. 如何解决
	- 增加**本地缓存**
	- 读写分离，增加副本数量

参考：[Redis 热 Key 发现以及解决办法](https://dongzl.github.io/2021/01/14/03-Redis-Hot-Key/index.html)